---
name: NeRF Simulator
tools: [Deep Learning, ROS]
image: https://user-images.githubusercontent.com/87276851/235468593-78dde9aa-a4a0-4ba4-9aea-ec0f72da72c5.gif
description: NeRF Simulator for Image based robot navigation
external_url: 
---

 <h1 align="center">Neural Radiance Field based Simulator</h1>

 <!-- <p style="text-align: center;">Neural Radiance Field based Simulator</p> -->
 <!-- ![My Skills](https://skillicons.dev/icons?i=github) -->
 <!-- <p style="text-align: center;">Yash Patel</p> -->


# Abstract

A NeRF is a neural network trained to replicate input views of a single scene via rendering loss. It directly maps spatial location and viewing direction to color and opacity, effectively acting as a “volume”. This allows for a differentiable rendering of new views. The project aims to utilize NeRFs to construct indoor real-world environments, which can then be navigated using a quadrotor in augmented reality. 

# Results




![nerf_process](https://user-images.githubusercontent.com/87276851/235246244-5d0736de-b5b1-4629-9ba0-653abef211a1.gif)

![scene_manipulation](https://user-images.githubusercontent.com/87276851/235257994-398165db-eb72-4ae2-a830-cec33e268512.gif)

![nerf_ros](https://user-images.githubusercontent.com/87276851/235250145-5daa28d5-d432-4c09-8675-b5b7cac54e2b.gif)


