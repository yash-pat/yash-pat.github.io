---
name: Deep V-SLAM
tools: [SLAM, Deep Learning, ROS]
image: https://user-images.githubusercontent.com/87276851/152707776-837c4e8b-6952-4c67-8c6f-b765eb420594.png
description: NeRF Simulator for Image based robot navigation
# external_url: https://drive.google.com/file/d/15IVhjKqoPyvoY-PHXU9jnbxDrrKSR908/view?usp=sharing
---

 <h1 align="center">Neural Radiance Field based Simulator</h1>

 <!-- <p style="text-align: center;">Neural Radiance Field based Simulator</p> -->
 <!-- ![My Skills](https://skillicons.dev/icons?i=github) -->
 <!-- <p style="text-align: center;">Yash Patel</p> -->


# Abstract

A NeRF is a neural network trained to replicate input views of a single scene via rendering loss. It directly maps spatial location and viewing direction to color and opacity, effectively acting as a “volume”. This allows for a differentiable rendering of new views. The project aims to utilize NeRFs to construct indoor real-world environments, which can then be navigated using a quadrotor in augmented reality. 

# Results



![object](https://user-images.githubusercontent.com/87276851/235009060-966939a2-29fa-4a45-ab3a-6fcc621e218d.gif)

